<!doctype html>
<html>

<head>
  <title>Yen-Chia Hsu</title>
  <meta charset="utf-8" name="viewport" content="width=device-width, initial-scale=1">
  <link href="css/frame.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/controls.css" media="screen" rel="stylesheet" type="text/css" />
  <link href="css/custom.css" media="screen" rel="stylesheet" type="text/css" />
  <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Open+Sans+Condensed:300,700' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,700" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="js/menu.js"></script>
  <script>
    (function (i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function () {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o),
        m = s.getElementsByTagName(o)[0];
      a.async = 1;
      a.src = g;
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-103598896-1', 'auto');
    ga('send', 'pageview');
  </script>
</head>

<body>
  <div class="menu-container"></div>
  <div class="content-container">
    <div class="content">
      <div class="content-table flex-column">
        <div class="flex-row">
          <div class="flex-item flex-column">
            <img class="image" id="me" src="img/me.jpeg">
          </div>
          <div class="flex-item flex-column">
            <h2>Yen-Chia Hsu</h2>
            <p class="text">
              Assistant Professor<br>
              y.c.hsu (at) uva.nl<br>
              <a href="https://ivi.uva.nl" target="_blank">Informatics Institute</a><br>
              <a href="https://www.uva.nl/en" target="_blank">University of Amsterdam</a><br>
              <a href="https://orcid.org/0000-0002-8016-7534">
                <img alt="ORCID logo" src="https://info.orcid.org/wp-content/uploads/2019/11/orcid_16x16.png" width="16" height="16" />
                https://orcid.org/0000-0002-8016-7534
              </a><br>
            </p>
          </div>
        </div>
        <div class="flex-row">
          <div class="flex-item flex-column">
            <p class="text">
              <span class="custom-text-danger">
                Emails that pretend to be from me and ask for money (e.g., cash and gift card) are spam.
                Please report them to the email service provider and pay extra attention to emails from other domains (e.g., @gmail.com) that claim to be from me.
              </span>
            </p>
            <h2>Biography</h2>
            <hr>
            <p class="text">
              I am a computer scientist with an architectural design background.
              I research how to embed technology in hyper-local contexts to facilitate civic engagement and community empowerment.
              <b>Specifically, my research is focused on Community-Empowered Artificial Intelligence (AI), where I co-design, implement, deploy, and evaluate interactive AI systems that empower communities, especially in addressing environmental and social issues.</b>
              My research concerns both the social and technical aspects.
              Regarding the social aspect, my vision is to create a community-based framework for conducting AI research with communities in the public health domain, which requires empirical studies of co-creating AI systems in local contexts.
              Regarding the technical aspect, I am interested in understanding the value of human feedback in AI pipelines, as well as algorithms that can enable machine learning models to take different types of human feedback.
            </p>
            <p class="text">
              Traditionally, scientists lead research to engage citizens in tackling environmental and social issues (e.g., air pollution) on a large scale.
              I have proposed an alternative, <a href="https://arxiv.org/abs/1907.11260" target="_blank">Community Citizen Science</a> (CCS), to extend this science-oriented method to a hyper-local scale.
              CCS aims to empower communities and scientists to produce scientific knowledge, represent their voices, address local concerns, and shape more equitable power relationships.
              In this way, CCS advances the current science-oriented method by emphasizing continued community engagement after technology interventions.
              In my research, I apply crowdsourcing and data visualization to engage communities in providing and exploring data.
              Also, I utilize machine learning, computer vision, and data science to assist communities in extracting and explaining patterns in multiple types of large-scale data.
              For more details, please refer to my <a href="https://drive.google.com/file/d/1Esa-xfOAR9rcZQxUP5tYLVubefom5Z4j/view?usp=drive_link" target="_blank">CV</a>,
              <a href="file/yenchiah-research-v5.pdf" target="_blank">research statement</a>,
              <a href="file/yenchiah-teaching-v6.pdf" target="_blank">teaching statement</a>,
              and <a href="file/yenchiah-diversity-v3.pdf" target="_blank">diversity statement</a>.
              For people who speak Mandarin Chinese, if you are interested in the CCS framework, here is the <a href="https://www.youtube.com/watch?v=kxxwc3fT-aA" target="_blank">video recording of my previous talk (in Mandarin Chinese)</a> in the National Tsing Hua University in Taiwan on early 2021.
              Also, here is <a href="https://www.youtube.com/watch?v=vHfCpwQqdLA" target="_blank">another video recording of a talk (in English)</a> that I gave to the air quality working group at the European Citizen Science Association on late 2021.
            </p>
            <p class="text">
              I am an Assistant Professor at the <a href="https://ivi.uva.nl" target="_blank">Informatics Institute</a>, <a href="https://www.uva.nl/en" target="_blank">University of Amsterdam</a>.
              Formerly, I was a Postdoctoral Researcher at the <a href="https://www.tudelft.nl/io/over-io/afdelingen/sustainable-design-engineering" target="_blank">Department of Sustainable Design Engineering</a>, <a href="https://www.tudelft.nl/en/ide/" target="_blank">Faculty of Industrial Design Engineering</a>, <a href="https://www.tudelft.nl/" target="_blank">TU Delft</a>, the Netherlands.
              Before TU Delft, I was a Project Scientist in the <a href="https://www.cmucreatelab.org/" target="_blank">CREATE Lab</a> at <a href="https://www.cmu.edu/" target="_blank">Carnegie Mellon University</a> (CMU), USA.
              I received my <a href="https://www.ri.cmu.edu/education/academic-programs/doctoral-robotics-program/" target="_blank">Ph.D. degree in Robotics</a> in 2018 from the <a href="https://www.ri.cmu.edu/" target="_blank">Robotics Institute</a> at CMU, where I conducted research on using technology to empower local citizens and communities.
              Previously, I received my Master's degree in <a href="https://soa.cmu.edu/mtid/" target="_blank">tangible interaction design</a> in 2012 from the <a href="https://soa.cmu.edu/" target="_blank">School of Architecture</a> at CMU, where I studied and built prototypes of interactive robots and wearable devices.
              Before CMU, I earned my dual Bachelor's degree in both <a href="http://www.arch.ncku.edu.tw/en" target="_blank">architecture</a> and <a href="http://www.csie.ncku.edu.tw/ncku_csie/?lang=en" target="_blank">computer science</a> in 2010 at <a href="http://web.ncku.edu.tw/bin/home.php?Lang=en" target="_blank">National Cheng Kung University</a>, Taiwan.
            </p>
            <p class="text">
              About my name, my given name is Yen-Chia, not Yen.
              My English name (Yen-Chia Hsu) comes from the Wade-Giles transcription of my name in Traditional Mandarin Chinese.
              In Taiwan, when using the Wade-Giles transcription system, we put a dash between our given name's characters.
              Also, in Traditional Mandarin Chinese, we put the family name before the given name, which is different from the English naming conventions.
              For pronunciation, Yen is like the Japanese yen, and Chia is like "ja" when saying Ninja.
              My family name (Hsu) is hard to pronounce since the English system does not have such types of vocalization.
              The closest sound is "she," not "su."
            </p>
            <h3>Table of Content</h3>
            <ul>
              <li><a href="#award">Awards and Honors</a></li>
              <li><a href="#journal-paper">Refereed Journal and Magazine Papers</a></li>
              <li><a href="#conference-paper">Refereed Conference Papers</a></li>
              <li><a href="#wip-paper">Refereed Posters, Works-in-Progress, and Workshop Papers</a></li>
              <li><a href="#other-paper">Other Publications</a></li>
              <li><a href="#feature-media">Featured Media and Book Coverage</a></li>
              <li><a href="#tool">Released Open Source Tools, Datasets, and Teaching Materials</a></li>
              <li><a href="#teaching">Teaching</a></li>
              <li><a href="#project">Projects</a></li>
            </ul>
            <h2 id="award">Awards and Honors</h2>
            <hr>
            <!--This list is reversed on the website due to reverse number listing-->
            <ol class="publication A-list">
              <li>
                <p class="text-small-margin">
                  Outstanding Student Academic Achievement.
                  2005, 2006, 2007. Department of Architecture, National Cheng Kung University, Taiwan.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Third Prize, National Country House Design Competition.
                  2008. Ministry of the Interior, Taiwan.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <a target="_blank" href="http://www.yestaiwan.com.tw/page06_5.html">Best New Artist</a>.
                  2009. The National Golden Award for Architecture, Taiwan.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <a target="_blank" href="https://winners.webbyawards.com/2014/websites-and-mobile-sites/features-design/best-use-of-video-or-moving-image/146235/timelapse">Webby People's Voice Award, Best Use of Video or Moving Image</a>.
                  2014. International Academy of Digital Arts and Sciences, USA.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <a target="_blank" href="https://dl.acm.org/citation.cfm?id=3025853">Best Paper Honorable Mention Award (Top 5%)</a>.
                  2017. ACM CHI Conference on Human Factors in Computing Systems, USA.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <a href="https://dl.acm.org/citation.cfm?id=3302293" target="_blank">Best Paper Honorable Mention Award (Top 2.5%, 7 out of 282 submissions)</a>.
                  2019. ACM IUI Conference on Intelligent User Interfaces, USA.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <a href="https://www.constellationprize.org/the-shenango-channel" target="_blank">Prize for Community Collaboration</a>.
                  2020. The Constellation Prize, USA.
                </p>
              </li>
            </ol>
            <h2 id="journal-paper">Refereed Journal and Magazine Papers</h2>
            <hr>
            <ol class="publication J-list">
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b> and Illah Nourbakhsh. 2020. When Human-Computer Interaction Meets Community Citizen Science. Communications of the ACM.
                  <br>
                  <a href="https://doi.org/10.1145/3376892" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1907.11260" target="_blank">arXiv</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://cacm.acm.org/magazines/2020/2/242344-when-human-computer-interaction-meets-community-citizen-science/fulltext" target="_blank">Webpage</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=tg_0s1VuPI8" target="_blank">Video</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Jennifer Cross, Paul Dille, Michael Tasota, Beatrice Dias, Randy Sargent, Ting-Hao Huang, and Illah Nourbakhsh. 2020. Smell Pittsburgh: Engaging Community Citizen Science for Air Quality. ACM Transactions on Interactive Intelligent Systems.
                  <br>
                  <a href="https://dl.acm.org/doi/10.1145/3369397" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1912.11936" target="_blank">arXiv</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Himanshu Verma, Andrea Mauri, Illah Nourbakhsh, and Alessandro Bozzon. 2022. Empowering local communities using artificial intelligence. Patterns, 3(3), 100449.
                  <br>
                  <a href="https://doi.org/10.1016/j.patter.2022.100449" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2110.02007" target="_blank">arXiv</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Andreas Gavros, <b>Yen-Chia Hsu</b>, and Kostas Karatzas. 2024. Modelling Smell Events in Urban Pittsburgh with Machine and Deep Learning Techniques. Atmosphere 15, no. 6: 731.
                  <br>
                  <a href="https://doi.org/10.3390/atmos15060731" target="_blank">Source</a>
                </p>
              </li>
            </ol>
            <!--This list is reversed on the website due to reverse number listing-->
            <h2 id="conference-paper">Refereed Conference Papers</h2>
            <hr>
            <!--This list is reversed on the website due to reverse number listing-->
            <ol class="publication C-list">
              <li>
                <p class="text-small-margin">
                  Yang-Ting Shen, Tay-Sheng Jeng, and <b>Yen-Chia Hsu</b>. 2011. A "Live" Interactive Tagging Interface for Collaborative Learning. International Conference on Cooperative Design, Visualization and Engineering (CDVE 2011). Springer.
                  <br>
                  <a href="https://link.springer.com/chapter/10.1007%2F978-3-642-23734-8_16" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2016/05/12/syntag-a-web-based-platform-for-labeling-real-time-video-acm-cscw-2012-short-paper/" target="_blank">Blog</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Tay-Sheng Jeng, Yang-Ting Shen, and Po-Chun Chen. 2012. SynTag: A Web-based Platform for Labeling Real-time Video. In Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work (CSCW 2012). ACM.
                  <br>
                  <a href="http://dl.acm.org/citation.cfm?id=2145312" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=k7zWjvpDYtE" target="_blank">Video</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2016/05/12/syntag-a-web-based-platform-for-labeling-real-time-video-acm-cscw-2012-short-paper/" target="_blank">Blog</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/yenchiah/SynTag" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Paul Dille, Jennifer Cross, Beatrice Dias, Randy Sargent, and Illah Nourbakhsh. 2017. Community-Empowered Air Quality Monitoring System. In Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems (CHI 2017). ACM.
                  <span class="custom-text-danger">(Best Paper Honorable Mention Award, Top 5%)</span>
                  <br>
                  <a href="http://dl.acm.org/citation.cfm?id=3025853" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1804.03293" target="_blank">arXiv</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=WxOw0j3oTXM" target="_blank">Video</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2017/02/02/community-empowered-air-quality-monitoring-system-acm-chi-2017-full-paper/" target="_blank">Blog</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="file/ACCAN-survey.pdf" target="_blank">Appendix</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="http://shenangochannel.org/" target="_blank">Website</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/CMU-CREATE-Lab/the-shenango-channel" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Jennifer Cross, Paul Dille, Michael Tasota, Beatrice Dias, Randy Sargent, Ting-Hao (Kenneth) Huang, and Illah Nourbakhsh. 2019. Smell Pittsburgh: Community-Empowered Mobile Smell Reporting System. In Proceedings of the 24th International Conference on Intelligent User Interfaces (IUI 2019). ACM.
                  <span class="custom-text-danger">(Best Paper Honorable Mention Award, Top 2.5%)</span>
                  [Note: this paper has errors, and we provide the corrections in the last two pages of the arXiv version]
                  <br>
                  <a href="https://dl.acm.org/citation.cfm?id=3302293" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1810.11143" target="_blank">arXiv</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=aOPyPfjJhBs" target="_blank">Video</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=JNbGIhK_lx8" target="_blank">Conference Talk</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2017/07/10/smell-pgh-a-mobile-application-to-crowdsource-and-visualize-pollution-odors/" target="_blank">Blog</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="file/smell-pgh-survey.pdf" target="_blank">Appendix</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://smellpgh.org/" target="_blank">Website</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/CMU-CREATE-Lab/smell-pittsburgh-prediction" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Ting-Yao Hsu, Chieh-Yang Huang, <b>Yen-Chia Hsu</b>, and Ting-Hao Huang. 2019. Visual Story Post-Editing. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics (ACL 2019).
                  <br>
                  <a href="http://dx.doi.org/10.18653/v1/P19-1658" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1906.01764" target="_blank">arXiv</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/tingyaohsu/VIST-Edit" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Ting-Hao (Kenneth) Huang, Ting-Yao Hu, Paul Dille, Sean Prendi, Ryan Hoffman, Anastasia Tsuhlares, Jessica Pachuta, Randy Sargent, and Illah Nourbakhsh. 2021. Project RISE: Recognizing Industrial Smoke Emissions. Proceedings of the AAAI Conference on Artificial Intelligence (AAAI 2021).
                  [Note: this paper has an error, and we provide the correction in the last page of the arXiv version]
                  <br>
                  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/17739" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2005.06111" target="_blank">arXiv</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/CMU-CREATE-Lab/deep-smoke-machine" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Philippe Lammerts, Philip Lippmann, <b>Yen-Chia Hsu</b>, Fabio Casati, and Jie Yang. 2023. How do you feel? Measuring User-Perceived Value for Rejecting Machine Decisions in Hate Speech Detection. In Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society (AIES 2023). ACM.
                  <br>
                  <a href="https://doi.org/10.1145/3600211.3604655" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2307.11806" target="_blank">arXiv</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Tim Alpherts, Sennay Ghebreab, <b>Yen-Chia Hsu</b>, and Nanne Van Noord. 2024. Perceptive Visual Urban Analytics is Not (Yet) Suitable for Municipalities. In Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency (FAccT 2024). ACM.
                  <br>
                  <a href="https://doi.org/10.1145/3630106.3658976" target="_blank">Source</a>
                </p>
              </li>
            </ol>
            <h2 id="wip-paper">Refereed Posters, Works-in-Progress, and Workshop Papers</h2>
            <hr>
            <!--This list is reversed on the website due to reverse number listing-->
            <ol class="publication P-list">
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Paul Dille, Randy Sargent, Christopher Bartley, and Illah Nourbakhsh. 2015. A Web-based Large-scale Timelapse Editor for Creating and Sharing Guided Video Tours and Interactive Slideshows. IEEE Information Visualization Posters, 2015.
                  <br>
                  <a href="file/timelapse-editor.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://vimeo.com/136251467" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2016/05/14/a-web-based-large-scale-timelapse-editor-for-creating-and-sharing-guided-video-tours-and-interactive-slideshows-ieee-vis-2015-poster/" target="_blank">Blog</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/CMU-CREATE-Lab/timemachine-viewer" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>, Jennifer Cross, Paul Dille, Illah Nourbakhsh, Leann Leiter, and Ryan Grode. 2018. Visualization Tool for Environmental Sensing and Public Health Data. In Proceedings of the 2018 ACM Conference Companion Publication on Designing Interactive Systems (DIS 2018 Companion). ACM.
                  <br>
                  <a href="file/env-health-channel.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://dl.acm.org/citation.cfm?id=3197391.3205419" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1804.03263" target="_blank">arXiv</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://yenchiah.wordpress.com/2017/08/31/environmental-health-channel-an-online-tool-for-visualizing-sensor-and-health-data/" target="_blank">Blog</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="file/env-health-channel-focus-group-questions.pdf" target="_blank">Appendix</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/CMU-CREATE-Lab/ehp-channel" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Ting-Yao Hsu, <b>Yen-Chia Hsu</b>, and Ting-Hao (Kenneth) Huang. 2019. On How Users Edit Computer-Generated Visual Stories. In Extended Abstracts of the 2019 CHI Conference on Human Factors in ComputingSystems (CHI EA 2019). ACM.
                  <br>
                  <a href="https://dl.acm.org/citation.cfm?id=3312965" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/1902.08327" target="_blank">arXiv</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Ting-Hao (Kenneth) Huang, Chieh-Yang Huang, Chien-Kuang Cornelia Ding, <b>Yen-Chia Hsu</b>, and C. Lee Giles. 2020. CODA-19: Using a Non-Expert Crowd to Annotate Research Aspects on 10,000+ Abstracts in the COVID-19 Open Research Dataset. In Proceedings of the 1st Workshop on NLP for COVID-19 at Association for Computational Linguistics (ACL 2020).
                  <br>
                  <a href="https://www.aclweb.org/anthology/2020.nlpcovid19-acl.6/" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2005.02367" target="_blank">arXiv</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/windx0303/CODA-19" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Andrea Mauri, Andrea Tocchetti, Lorenzo Corti, <b>Yen-Chia Hsu</b>, Himanshu Verma, and Marco Brambilla. 2022. COCTEAU: an Empathy-Based Tool for Decision-Making. Posters and Demos Track at The Web Conference 2022 (WWW 2022).
                  <br>
                  <a href="https://arxiv.org/abs/2204.06289" target="_blank">arXiv</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Andrea Mauri, <b>Yen-Chia Hsu</b>, Marco Brambilla, Aisling Ann O'Kane, Ting-Hao (Kenneth) Huang, and Himanshu Verma. 2022. Empathy-Centric Design At Scale. In Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems (CHI EA 2022). ACM.
                  <br>
                  <a href="https://dl.acm.org/doi/10.1145/3491101.3503744" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://arxiv.org/abs/2204.06382" target="_blank">arXiv</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Alok Debnath, Allison Lahnala, Hüseyin Uğur Genç, Ewan Soubutts, Michal Lahav, Tiffanie Horne, Wo Meijer, Yun Suen Pai, <b>Yen-Chia Hsu</b>, Giulia Barbareschi, Himanshu Verma, and Andrea Mauri. 2024. EmpathiCH: Scrutinizing Empathy-Centric Design Beyond the Individual. In Extended Abstracts of the 2024 CHI Conference on Human Factors in Computing Systems (CHI EA 2024). ACM.
                  <br>
                  <a href="https://doi.org/10.1145/3613905.3636297" target="_blank">Source</a>
                </p>
              </li>
            </ol>
            <h2 id="other-paper">Other Publications</h2>
            <hr>
            <!--This list is reversed on the website due to reverse number listing-->
            <ol class="publication O-list">
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>. 2016. Industrial Smoke Detection and Visualization. Technical Report CMU-RI-TR-16-55. Robotics Institute, Carnegie Mellon University, Pittsburgh, PA.
                  <br>
                  <a href="file/industrial-smoke-detection-and-visualization.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.ri.cmu.edu/publications/industrial-smoke-detection-and-visualization/" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/yenchiah/industrial-smoke-detection" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>. 2018. SimArch: A Multi-agent System For Human Path Simulation In Architecture Design. arXiv preprint arXiv:1807.03760.
                  <br>
                  <a href="https://arxiv.org/abs/1807.03760" target="_blank">arXiv</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://github.com/yenchiah/SimArch" target="_blank">Code and Data</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Emiliano Huet-Vaughn, Nicholas Muller, and <b>Yen-Chia Hsu</b>. 2018. Livestreaming Pollution: A New Form of Public Disclosure and a Catalyst for Citizen Engagement. No. w24664. National Bureau of Economic Research, 2018.
                  <br>
                  <a href="http://www.nber.org/papers/w24664" target="_blank">Preprint</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>. 2018. Designing Interactive Systems for Community Citizen Science. Ph.D. Dissertation. Robotics Institute, Carnegie Mellon University, Pittsburgh, PA.
                  <br>
                  <a href="https://www.ri.cmu.edu/wp-content/uploads/2018/08/yc_hsu_robotics_2018.pdf" target="_blank">PDF</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://figshare.com/articles/Designing_Interactive_Systems_for_Community_Citizen_Science/7195082/1" target="_blank">Source</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.ri.cmu.edu/publications/designing-interactive-systems-for-community-citizen-science/" target="_blank">Preprint</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://www.youtube.com/watch?v=QOFfCD8r240" target="_blank">Video</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Yen-Chia Hsu</b>. 2021. 社區公民科學: 用開放數位平台的技術與公民合作解決都市環境問題. 眼底城事.
                  <br>
                  <a href="https://eyesonplace.net/2021/03/19/16600/?fbclid=IwAR1BGVj4_j385ApEYIjtYpdN6UM_0Fx7llPCJqV2KoBvYHWFB-azvPwMNAk" target="_blank">Source</a>
                </p>
              </li>
            </ol>
            <h2 id="feature-media">Featured Media and Book Coverage</h2>
            <hr>
            <p class="text">
              For a complete list of media and book coverage, please refer to my <a href="https://drive.google.com/file/d/1Esa-xfOAR9rcZQxUP5tYLVubefom5Z4j/view?usp=drive_link" target="_blank">CV</a>.
            </p>
            <!--This list is reversed on the website due to reverse number listing-->
            <ol class="publication F-list">
              <li>
                <p class="text-small-margin">
                  <b>TIME</b>. Jeffrey Kluger. 2013.
                  <a target="_blank" href="http://world.time.com/timelapse/">Timelapse: Landsat Satellite Images of Climate Change</a>.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Pittsburgh Post-Gazette</b>. Ashley Murray. 2017.
                  <a target="_blank" href="http://www.post-gazette.com/business/tech-news/2017/07/03/smell-pgh-app-carnegie-mellon-university-cmu-create-lab-foul-smell-pittsburgh/stories/201706300430">Carnegie Mellon Scientists Use App to Track Foul Odors in Pittsburgh</a>.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>PC Magazine</b>. Michelle Donahue. 2018.
                  <a target="_blank" href="https://www.pcmag.com/article/360317/citizen-science-do-try-this-at-home">Citizen Science: Do Try This at Home</a>.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Pittsburgh Earth Day</b>. Amanda Waltz. 2021.
                  <a target="_blank" href="https://pittsburghearthday.org/partnership-wins-award-for-using-tech-to-track-pittsburgh-air-pollution/">Partnership Wins Award for Using Tech to Track Pittsburgh Air Pollution</a>.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>EenVandaag</b>. Michiel Princen and Simone Timmer. 2023.
                  <a target="_blank" href="https://eenvandaag.avrotros.nl/item/in-pittsburgh-lukte-het-omwonenden-om-zwaar-vervuilende-kooksfabriek-te-laten-sluiten-we-gingen-langzaam-dood/">In Pittsburgh lukte het omwonenden om zwaar vervuilende kooksfabriek te laten sluiten: 'We gingen langzaam dood'</a>.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>EenVandaag</b>. Michiel Princen and Simone Timmer. 2023.
                  Gezondheid omwonenden verbetert meteen als een kooksfabriek - zoals die van Tata Steel - sluit, toont Amerikaans onderzoek aan.
                  <br>
                  <a href="https://eenvandaag.avrotros.nl/item/gezondheid-omwonenden-verbetert-meteen-als-kooksfabriek-zoals-die-van-tata-steel-sluit-toont-amerikaans-onderzoek-aan/" target="_blank">Link to the news article</a>
                  &nbsp;&nbsp;|&nbsp;&nbsp;
                  <a href="https://eenvandaag.avrotros.nl/item/eenvandaag-15-12-2023/" target="_blank">Link to the TV program (from 00:08 to 11:40)</a>
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  <b>Greenpeace Nederland</b>. Bram Karst. 2024.
                  <a target="_blank" href="https://www.greenpeace.org/nl/greenpeace/64054/omwonenden-sporen-illegale-gifwolken-tata-steel-op-met-behulp-van-artificial-intelligence/">Omwonenden sporen illegale gifwolken Tata Steel op met behulp van Artificial Intelligence</a>.
                </p>
              </li>
              <!--<li>
                <p class="text-small-margin">
                  <b>Publisher</b>. Name. 2021.
                  <a target="_blank" href=""></a>.
                </p>
              </li>-->
            </ol>
            <h2 id="tool">Released Open Source Tools, Datasets, and Teaching Materials</h2>
            <hr>
            <!--This list is reversed on the website due to reverse number listing-->
            <ol class="publication T-list">
              <li>
                <p class="text-small-margin">
                  Yen-Chia Hsu.
                  <a target="_blank" href="https://github.com/yenchiah/SynTag">A Web-based Platform for Labeling Real-time Video</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Yen-Chia Hsu.
                  <a target="_blank" href="https://github.com/yenchiah/SimArch">A Multi-agent System for Human Path Simulation In Architecture Design</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Yen-Chia Hsu.
                  <a target="_blank" href="https://github.com/yenchiah/SENSEable-Shoes">A Wearable Shoe-Integrated Interaction Interface</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Yen-Chia Hsu.
                  <a target="_blank" href="https://github.com/yenchiah/timeline-heatmap">A JavaScript Library for Creating an Interactive Timeline Heatmap</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Yen-Chia Hsu.
                  <a target="_blank" href="https://github.com/yenchiah/geo-heatmap">A JavaScript Library for Creating an Interactive Geographical Heatmap</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Yen-Chia Hsu.
                  <a target="_blank" href="https://github.com/yenchiah/project-website-template">A HTML/CSS Template for Building Projects or Personal Websites</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  CMU CREATE Lab.
                  <a target="_blank" href="https://github.com/CMU-CREATE-Lab/timemachine-viewer">A Web-Based Interactive Viewer for Visualizing Large-Scale Timelapses</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  CMU CREATE Lab.
                  <a target="_blank" href="https://github.com/CMU-CREATE-Lab/ehp-channel">Visualization Tool for Environmental Sensing and Public Health Data</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  CMU CREATE Lab.
                  <a target="_blank" href="https://github.com/CMU-CREATE-Lab/smell-pittsburgh-rails">A Mobile Application to Crowdsource and Visualize Pollution Odors</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  CMU CREATE Lab.
                  <a target="_blank" href="https://github.com/CMU-CREATE-Lab/data-visualization-tools">Earth Timelapse Viewer</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  CMU CREATE Lab.
                  <a target="_blank" href="https://github.com/CMU-CREATE-Lab/smell-pittsburgh-prediction">Predicting and Interpreting Smell Data Obtained from Smell Pittsburgh</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  CMU CREATE Lab.
                  <a target="_blank" href="https://github.com/CMU-CREATE-Lab/video-labeling-tool">A Tool for Labeling Video Clips (both Front-end and Back-end)</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  CMU CREATE Lab.
                  <a target="_blank" href="https://github.com/CMU-CREATE-Lab/deep-smoke-machine">Deep Learning Models and Dataset for Recognizing Industrial Smoke Emissions</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  TUD KInD.
                  <a target="_blank" href="https://github.com/TUD-KInD/COCTEAU-TUD">A Tool for Citizen Engagement at Scale</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Yen-Chia Hsu.
                  <a target="_blank" href="https://github.com/yenchiah/project-application-template">A Template to Start a Web-based Project That Has Both Back-end and Front-end</a>.
                  Computer software.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Multimedia Analytics Lab Amsterdam.
                  <a target="_blank" href="https://github.com/MultiX-Amsterdam/data-science-book-uva">Data Science Course</a>.
                  Teaching material.
                </p>
              </li>
              <li>
                <p class="text-small-margin">
                  Yen-Chia Hsu.
                  <a target="_blank" href="https://github.com/yenchiah/jupyter-book-template">Tutorial and Template for Building a Jupyter Book Website</a>.
                  Teaching material.
                </p>
              </li>
            </ol>
          </div>
          <!--Start Teaching and Projects-->
          <div class="flex-row full-width">
            <div class="flex-item flex-column full-width">
              <h2 id="teaching">Teaching</h2>
              <hr>
              <ul>
                <li>
                  <a href="https://coursecatalogue.uva.nl/xmlpages/page/2023-2024/zoek-vak/vak/110339" target="_blank">Information Visualization</a>, 2022/2023, 2023/2024, Informatics Institute, University of Amsterdam
                </li>
                <li>
                  <a href="https://multix.io/data-science-book-uva/" target="_blank">Data Science</a>, 2022/2023, 2023/2024, Informatics Institute, University of Amsterdam
                </li>
              </ul>
              <h2 id="project">Projects</h2>
              <hr>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/cocteau.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">COCTEAU: an Empathy-Based Tool for Decision-Making [P5, P6, T14], 2021 - 2022</span><br>
                I worked in a team to build a tool to strengthen interactions between citizens and decision-makers on a large scale.
                The goal is to elicit empathetic relations among stakeholders to collect perspectives on societal issues.
                (<a href="https://periscope.io.tudelft.nl/" target="_blank">link to website</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/smoke-labeling.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">Project RISE: Recognizing Industrial Smoke Emissions [C6, T13], 2018 - 2020</span><br>
                I co-designed a system with local communities in labeling videos with industrial smoke emissions.
                These labels were used to train a deep neural network to recognize smoke and industrial pollution events for air quality advocacy.
                (<a href="https://smoke.createlab.org/" target="_blank">link to website</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/smell-pgh.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">Community-Empowered Mobile Smell Reporting System [C4, F2, T9, A6], 2017 - 2020</span><br>
                I worked in a team to develop Smell Pittsburgh, a mobile application for citizens to report pollution odors to regulators.
                A map visualizes the reports with air quality and wind data.
                A machine learning model predicts odors and sends push notifications.
                (<a href="http://smellpgh.org" target="_blank">link to website</a>, <a href="https://yenchiah.wordpress.com/2017/07/10/smell-pgh-a-mobile-application-to-crowdsource-and-visualize-pollution-odors/" target="_blank">link to blog</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/earthtime-editor.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">A Tool for Creating Interactive Stories on the EarthTime Timelapse [T10], 2018</span><br>
                I worked in a team to develop a web-based tool that enables users to create, edit, and share
                stories about nature changes and human impact on EarthTime, visualizing the transformation of
                the EarthTime over three decades with images and datasets.
                (<a href="https://earthtime.org" target="_blank">website link</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/env-health-channel.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">Visualization Tool for Environmental Sensing and Public Health Data [P2, T5, T8], 2017</span><br>
                I worked in a team to develop the Environmental Health Channel, an interactive web-based tool for visualizing health symptoms, particulate measurements, and personal stories from residents who are affected by oil and gas drilling development.
                (<a href="https://yenchiah.wordpress.com/2017/08/31/environmental-health-channel-an-online-tool-for-visualizing-sensor-and-health-data/" target="_blank">link to blog</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/air-quality-monitor.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">Community-Empowered Air Quality Monitoring System [C3, F3, A5], 2015 - 2016</span><br>
                I worked with local citizens to build an air quality monitoring system that integrates camera data, sensing data, and smell reports.
                The system used computer vision to generate videos with smoke emissions to serve as evidence of pollution.
                (<a href="http://shenangochannel.org/" target="_blank">link to website</a>, <a href="https://yenchiah.wordpress.com/2017/02/02/community-empowered-air-quality-monitoring-system-acm-chi-2017-full-paper/" target="_blank">link to blog</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/timelapse-editor.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">A Web-based Large-scale Timelapse Editor for Interactive Storytelling [P1, T7], 2014</span><br>
                Based on the timelapse viewer, I developed a tool for users to create interactive slideshows or guided tours.
                Users can embed or share the slideshows or tours on social media for telling interactive stories.
                (<a href="https://yenchiah.wordpress.com/2016/05/14/a-web-based-large-scale-timelapse-editor-for-creating-and-sharing-guided-video-tours-and-interactive-slideshows-ieee-vis-2015-poster/" target="_blank">link to blog</a>, <a href="https://explorables.cmucreatelab.org/explorables/timelapse-story-telling.html" target="_blank">link to demo</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/timelapse-viewer.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">Earth Timelaspe Viewer Visualizing Landsat Satellite Imagery [F1, T7, A4], 2013</span><br>
                I worked in a team to develop an Earth timelapse viewer, consisting of cloud-free mosaics of the planet with billions of pixels for decades.
                The interactive viewer was released with Google and TIME.
                (<a href="https://earthengine.google.com/timelapse/" target="_blank">link to Google Earth Engine</a>, <a href="http://world.time.com/timelapse/" target="_blank">link to TIME</a>, <a href="https://yenchiah.wordpress.com/2016/05/13/earth-timelaspe-viewer-visualizing-landsat-satellite-imagery-webby-peoples-voice-award-2014/" target="_blank">link to blog</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/simarch.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">SimArch: A Multi-Agent System for Human Path Simulation [O2, T2], 2012</span><br>
                SimArch uses Markov Decision Process to build a behavior model.
                The model simulates mental states, target range detection, and collision prediction when agents behave in a museum.
                SimArch outputs the prediction of how likely a person will occur in a location.
                (<a href="https://yenchiah.wordpress.com/2016/05/11/simarch-a-multi-agent-system-for-human-path-simulation-in-architecture-design/" target="_blank">link to blog</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/senseable-shoes.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">SENSEable Shoes: Hands-Free and Eyes-Free Mobile Interaction [T3], 2012</span><br>
                SENSEable Shoes is a platform for designers to create applications.
                It recognizes low-level activities by measuring the weight distribution over the feet with sensors in the shoe pad.
                A Support Vector Machine classifier identifies mobile activities and foot gestures.
                (<a href="https://yenchiah.wordpress.com/2016/05/09/senseable-shoes-hands-free-and-eyes-free-mobile-interaction/" target="_blank">link to blog</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/drawolin.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">Draw-o-lin: A Music Visualizer for Violin, 2011</span><br>
                What does music look like?
                Draw-o-lin is an interactive mobile robot visualizing music by drawing graphs on a paper according to various sound properties.
                Violin performers control the robot by playing various pitches, alternating the volume, and changing the tempo.
                (<a href="https://yenchiah.wordpress.com/2016/05/08/draw-o-lin-a-music-visualizer-for-violin/" target="_blank">link to blog</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/syntag.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">SynTag: A Web-Based Platform for Labeling Real-time Video [C2, C1, T1], 2010</span><br>
                Users can label Good, Question, and Disagree tags in real or non-real time with visualization of video previews on an interactive timeline.
                SynTag creates thumbnails by using real-time tags for presenters to receive instant feedback and for others to retrieve videos.
                (<a href="https://yenchiah.wordpress.com/2016/05/12/syntag-a-web-based-platform-for-labeling-real-time-video-acm-cscw-2012-short-paper/" target="_blank">link to blog</a>)
              </p>
            </div>
          </div>
          <div class="flex-row">
            <div class="flex-item flex-item-stretch flex-column">
              <img class="image max-width-600" src="img/architecture.jpg">
            </div>
            <div class="flex-item flex-item-stretch-6 flex-column">
              <p class="text">
                <span class="highlight-text">Architecture Design School Projects, 2007 - 2010</span><br>
                This collection includes a micro-city, a skyscraper design extending the concept of a micro-city, a dynamic facade responding to the physical environment, a worm-shaped machine that carries plants on the facade, and a self-sufficient country house design.
                (<a href="file/architecture-portfolio.pdf" target="_blank">link to file</a>)
              </p>
            </div>
          </div>
          <!--End Projects-->
        </div>
      </div>
    </div>
  </div>
</body>

</html>